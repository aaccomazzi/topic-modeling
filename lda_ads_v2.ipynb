{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark LDA for NASA ADS v1.0 \n",
    "8/2/2016\n",
    "@author: Tarun Ruchandani\n",
    "\n",
    "To Do:\n",
    "x Generate document term matrix for LDA\n",
    "x Get LDA Results on small Corpus\n",
    "\n",
    "8/3:\n",
    "\n",
    "o Generate a JS Matrix per mapequation's input\n",
    "- Generate topic trend reports.\n",
    "o Build Mapequation with JS Matrix\n",
    "o Extend to a larger corpus\n",
    "o Build Docker Container\n",
    "o Deploy to adsqb\n",
    "\n",
    "- JS Matrix: figure out the right implementation - also try ifa library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#All 'em libraries\n",
    "\n",
    "import numpy as np\n",
    "import textmining\n",
    "import pyspark\n",
    "import lda\n",
    "import lda.datasets\n",
    "import ads\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from numpy  import array\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarunruchandani/anaconda3/lib/python3.5/site-packages/ads/utils.py:23: UserWarning: You are lazy loading attributes via 'abstract', and so are making multiple calls to the API. This will impact your overall rate limits.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Extract Cosmology papers\n",
    "ads.config.token = 'TkEI7jQxScyoCtzHfhcpCWVelRqySmH5XBksQCFA'\n",
    "papers = list(ads.SearchQuery(q='cosmology',start=100,rows=100))\n",
    "\n",
    "paper_abstracts=list()\n",
    "\n",
    "for paper in papers:\n",
    "    paper_abstracts.append(paper.abstract)\n",
    "\n",
    "# Select first 25 papers which have abstracts. Some later ones don't. Revisit this when scaling.\n",
    "# paper_abstracts = paper_abstracts[0:25]\n",
    "print(len(paper_abstracts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build Term-Document Matrix\n",
    "\n",
    "tdm = textmining.TermDocumentMatrix()\n",
    "for paper in paper_abstracts:\n",
    "    tdm.add_doc(paper)\n",
    "    \n",
    "paper_abstracts_tdm = list()\n",
    "\n",
    "for row in tdm.rows(cutoff=0):\n",
    "    paper_abstracts_tdm.append(row)\n",
    "\n",
    "paper_abstracts_tdm_df = pd.DataFrame(paper_abstracts_tdm)\n",
    "paper_abstracts_tdm_df.head()\n",
    "\n",
    "# Vocab of terms in abstracts\n",
    "vocab = paper_abstracts_tdm_df._slice(slice(1))\n",
    "vocab\n",
    "\n",
    "d_t_freq = paper_abstracts_tdm_df._slice(slice(1,24))\n",
    "\n",
    "b=d_t_freq.values\n",
    "\n",
    "b=b.astype(int)\n",
    "\n",
    "\n",
    "# d_t_freq_m = d_t_freq.as_matrix\n",
    "# d_t_freq_np = np.ndarray(b, dtype=np.int64)\n",
    "# d_t_freq_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# running LDA on TDM\n",
    "# Parameters:\t\n",
    "# rdd – RDD of documents, which are tuples of document IDs and term (word) count vectors. \n",
    "# The term count vectors are “bags of words” with a fixed-size vocabulary \n",
    "# (where the vocabulary size is the length of the vector). Document IDs must be unique and >= 0.\n",
    "\n",
    "# k – Number of topics to infer, i.e., the number of soft cluster centers. (default: 10)\n",
    "\n",
    "# maxIterations – Maximum number of iterations allowed. (default: 20)\n",
    "\n",
    "# docConcentration – Concentration parameter (commonly named “alpha”) \n",
    "# for the prior placed on documents’ distributions over topics (“theta”). (default: -1.0)\n",
    "\n",
    "# topicConcentration – Concentration parameter (commonly named “beta” or “eta”) \n",
    "# for the prior placed on topics’ distributions over terms. (default: -1.0)\n",
    "\n",
    "# seed – Random seed for cluster initialization. Set as None to generate seed based on system time. (default: None)\n",
    "\n",
    "# checkpointInterval – Period (in iterations) between checkpoints. (default: 10)\n",
    "\n",
    "# optimizer – LDAOptimizer used to perform the actual calculation. Currently “em”, “online” are supported. \n",
    "# (default: “em”)\n",
    "\n",
    "model = lda.LDA(n_topics=20, n_iter=500, random_state=1)\n",
    "model.fit(b)\n",
    "\n",
    "topic_word = model.topic_word_  # model.components_ also works\n",
    "\n",
    "\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "     topic_words = np.array(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(doc_topic): <class 'numpy.ndarray'>\n",
      "shape: (23, 20)\n"
     ]
    }
   ],
   "source": [
    "doc_topic = model.doc_topic_\n",
    "print(\"type(doc_topic): {}\".format(type(doc_topic)))\n",
    "print(\"shape: {}\".format(doc_topic.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document: 0 sum: 0.9999999999999996\n",
      "document: 1 sum: 0.9999999999999998\n",
      "document: 2 sum: 1.0000000000000002\n",
      "document: 3 sum: 1.0\n",
      "document: 4 sum: 0.9999999999999994\n",
      "doc: 0 topic: 19\n",
      "...\n",
      "doc: 1 topic: 6\n",
      "...\n",
      "doc: 2 topic: 4\n",
      "...\n",
      "doc: 3 topic: 6\n",
      "...\n",
      "doc: 4 topic: 6\n",
      "...\n",
      "doc: 5 topic: 6\n",
      "...\n",
      "doc: 6 topic: 6\n",
      "...\n",
      "doc: 7 topic: 13\n",
      "...\n",
      "doc: 8 topic: 6\n",
      "...\n",
      "doc: 9 topic: 6\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Document-topic Probab\n",
    "\n",
    "doc_topic = model.doc_topic_\n",
    "\n",
    "for n in range(5):\n",
    "    sum_pr = sum(doc_topic[n,:])\n",
    "    print(\"document: {} sum: {}\".format(n, sum_pr))\n",
    "\n",
    "for n in range(10):\n",
    "    topic_most_pr = doc_topic[n].argmax()\n",
    "    print(\"doc: {} topic: {}\\n...\".format(n,\n",
    "                                            topic_most_pr\n",
    "                                            ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9541148438200611"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building JS Matrix\n",
    "\n",
    "\n",
    "def multi_js(p, q):\n",
    "    \"\"\"Jensen-Shannon divergence (symmetric) between two multinomials,\n",
    "    expressed in nats.\"\"\"\n",
    "    if (len(q.shape) == 2):\n",
    "        axis = 1\n",
    "    else:\n",
    "        axis = 0\n",
    "    # D_{JS}(P\\|Q) = (D_{KL}(P\\|Q) + D_{KL}(Q\\|P)) / 2\n",
    "    return 0.5 * ((q * (np.log(q.clip(1e-10,1))\n",
    "                        - np.log(p.clip(1e-10,1)))).sum(axis)\n",
    "                      + (p * (np.log(p.clip(1e-10,1))\n",
    "                              - np.log(q.clip(1e-10,1)))).sum(axis))\n",
    "\n",
    "\n",
    "JS_D1D2 = multi_js(doc_topic[0],doc_topic[1])\n",
    "JS_D1D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60293308491694719"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative JS implementation\n",
    "\n",
    "def jsd(x,y): #Jensen-shannon divergence\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", category = RuntimeWarning)\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    d1 = x*np.log2(2*x/(x+y))\n",
    "    d2 = y*np.log2(2*y/(x+y))\n",
    "    d1[np.isnan(d1)] = 0\n",
    "    d2[np.isnan(d2)] = 0\n",
    "    d = 0.5*np.sum(d1+d2)    \n",
    "    return d\n",
    "\n",
    "jsd(doc_topic[0],doc_topic[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, 0.0), (0, 1, 0.60293308491694719), (0, 2, 0.48943516134082565), (0, 3, 0.39298711843958667), (0, 4, 0.49684648549978927), (0, 5, 0.55107657859605375), (0, 6, 0.55144752863278979), (0, 7, 0.64456330984810206), (0, 8, 0.72024317949805527), (0, 9, 0.43490975188432368), (0, 10, 0.49101141981905727), (0, 11, 0.60822074484477839), (0, 12, 0.40516684161102456), (0, 13, 0.44303672131471122), (0, 14, 0.4302340827337664), (0, 15, 0.53153753140193538), (0, 16, 0.3843143784569622), (0, 17, 0.52873183935586476), (0, 18, 0.49486887476451263), (0, 19, 0.42697360239745585), (0, 20, 0.5034051653071242), (0, 21, 0.61456366481394875), (0, 22, 0.53195399357818995), (1, 0, 0.60293308491694719), (1, 1, 0.0), (1, 2, 0.44408218792809329), (1, 3, 0.39377654056400546), (1, 4, 0.24645438108943146), (1, 5, 0.29243696046069767), (1, 6, 0.26693326533002648), (1, 7, 0.49836923270994471), (1, 8, 0.27899994084519042), (1, 9, 0.45492180175777064), (1, 10, 0.28145435588301732), (1, 11, 0.34413738276731265), (1, 12, 0.30992772809613028), (1, 13, 0.27715326448639199), (1, 14, 0.49860727224071699), (1, 15, 0.3627745843843298), (1, 16, 0.46789453216808929), (1, 17, 0.40408034067256232), (1, 18, 0.44905822466934164), (1, 19, 0.35398731697696351), (1, 20, 0.4510142081442588), (1, 21, 0.37327363445741185), (1, 22, 0.41825332161295758), (2, 0, 0.48943516134082565), (2, 1, 0.44408218792809329), (2, 2, 0.0), (2, 3, 0.42400974457925861), (2, 4, 0.42203616176090475), (2, 5, 0.39915259884920717), (2, 6, 0.52207872263576627), (2, 7, 0.5186164261903734), (2, 8, 0.34900565310012027), (2, 9, 0.26945834097504312), (2, 10, 0.37184212240323972), (2, 11, 0.45643373208628807), (2, 12, 0.35833611674907895), (2, 13, 0.29989380012505135), (2, 14, 0.5414499703223058), (2, 15, 0.42475665531541756), (2, 16, 0.51818690483764562), (2, 17, 0.36325760912508037), (2, 18, 0.47468331333386554), (2, 19, 0.46678797758308171), (2, 20, 0.36316649176626992), (2, 21, 0.49987743342508789), (2, 22, 0.35073571849682594), (3, 0, 0.39298711843958667), (3, 1, 0.39377654056400546), (3, 2, 0.42400974457925861), (3, 3, 0.0), (3, 4, 0.51627629419402354), (3, 5, 0.33755245187646693), (3, 6, 0.4395714903472448), (3, 7, 0.30308136121799184), (3, 8, 0.55391298296046854), (3, 9, 0.39852234973361422), (3, 10, 0.46026582989676884), (3, 11, 0.39068372270973495), (3, 12, 0.40190700787487155), (3, 13, 0.54424460974930799), (3, 14, 0.50867666525308775), (3, 15, 0.55003807002220451), (3, 16, 0.43473692715995743), (3, 17, 0.41142644218040297), (3, 18, 0.51346390591116253), (3, 19, 0.28009056190902981), (3, 20, 0.37475309620845215), (3, 21, 0.40949978633446504), (3, 22, 0.21212554940809389), (4, 0, 0.49684648549978927), (4, 1, 0.24645438108943146), (4, 2, 0.42203616176090475), (4, 3, 0.51627629419402354), (4, 4, 0.0), (4, 5, 0.35402340441441754), (4, 6, 0.4504198702398669), (4, 7, 0.68893502740294521), (4, 8, 0.37504293481850237), (4, 9, 0.34546784262655872), (4, 10, 0.39528042488474513), (4, 11, 0.4630200087555324), (4, 12, 0.29654773276473523), (4, 13, 0.232816329840077), (4, 14, 0.50822385272597392), (4, 15, 0.42701910732309922), (4, 16, 0.58247591835479695), (4, 17, 0.37308908188252632), (4, 18, 0.55343500673824031), (4, 19, 0.33625254230617402), (4, 20, 0.48408416705775908), (4, 21, 0.44674146519510682), (4, 22, 0.53929876130725574), (5, 0, 0.55107657859605375), (5, 1, 0.29243696046069767), (5, 2, 0.39915259884920717), (5, 3, 0.33755245187646693), (5, 4, 0.35402340441441754), (5, 5, 0.0), (5, 6, 0.38692643517241881), (5, 7, 0.41034418462512651), (5, 8, 0.29679322483448894), (5, 9, 0.29245102529924533), (5, 10, 0.39308837318575984), (5, 11, 0.29645050728184663), (5, 12, 0.39270899307173501), (5, 13, 0.37690163248559189), (5, 14, 0.4533594173035006), (5, 15, 0.40728929724208518), (5, 16, 0.44873428353228123), (5, 17, 0.23311478850431194), (5, 18, 0.38424367676342408), (5, 19, 0.42501264054627463), (5, 20, 0.35615707483282166), (5, 21, 0.38559596667921958), (5, 22, 0.31879576644611179), (6, 0, 0.55144752863278979), (6, 1, 0.26693326533002648), (6, 2, 0.52207872263576627), (6, 3, 0.4395714903472448), (6, 4, 0.4504198702398669), (6, 5, 0.38692643517241881), (6, 6, 0.0), (6, 7, 0.60918689756699473), (6, 8, 0.44299136936212291), (6, 9, 0.42073661567767823), (6, 10, 0.29791550212446383), (6, 11, 0.37212893559836224), (6, 12, 0.30641101615685129), (6, 13, 0.40480246851482971), (6, 14, 0.45322191058983952), (6, 15, 0.40275631001837409), (6, 16, 0.44470808013632679), (6, 17, 0.45009484677723283), (6, 18, 0.44210148603326516), (6, 19, 0.36253077620822166), (6, 20, 0.50860797384608902), (6, 21, 0.42152901386012731), (6, 22, 0.53243745287325828), (7, 0, 0.64456330984810206), (7, 1, 0.49836923270994471), (7, 2, 0.5186164261903734), (7, 3, 0.30308136121799184), (7, 4, 0.68893502740294521), (7, 5, 0.41034418462512651), (7, 6, 0.60918689756699473), (7, 7, 0.0), (7, 8, 0.43507801435538912), (7, 9, 0.43842383888998598), (7, 10, 0.3673973629641355), (7, 11, 0.50049816024021276), (7, 12, 0.63903496903153123), (7, 13, 0.68163183619038703), (7, 14, 0.59961751759143889), (7, 15, 0.66179199668976285), (7, 16, 0.48870168957975713), (7, 17, 0.48198982460904777), (7, 18, 0.43468183821851469), (7, 19, 0.50755456678349375), (7, 20, 0.34535036897010468), (7, 21, 0.42532925216284351), (7, 22, 0.19023768803283542), (8, 0, 0.72024317949805527), (8, 1, 0.27899994084519042), (8, 2, 0.34900565310012027), (8, 3, 0.55391298296046854), (8, 4, 0.37504293481850237), (8, 5, 0.29679322483448894), (8, 6, 0.44299136936212291), (8, 7, 0.43507801435538912), (8, 8, 0.0), (8, 9, 0.26180152369302429), (8, 10, 0.29444370643363937), (8, 11, 0.4162823961612041), (8, 12, 0.36896164257037822), (8, 13, 0.41898287280586677), (8, 14, 0.57465678073217796), (8, 15, 0.37077118739053427), (8, 16, 0.57305098826110501), (8, 17, 0.36032569480736065), (8, 18, 0.46364996738422837), (8, 19, 0.46900464644541762), (8, 20, 0.53351194845755079), (8, 21, 0.3624547026305675), (8, 22, 0.44839013293799779), (9, 0, 0.43490975188432368), (9, 1, 0.45492180175777064), (9, 2, 0.26945834097504312), (9, 3, 0.39852234973361422), (9, 4, 0.34546784262655872), (9, 5, 0.29245102529924533), (9, 6, 0.42073661567767823), (9, 7, 0.43842383888998598), (9, 8, 0.26180152369302429), (9, 9, 0.0), (9, 10, 0.32659306639884361), (9, 11, 0.44560415927888802), (9, 12, 0.33587093803198598), (9, 13, 0.41447589888102954), (9, 14, 0.4191657680715089), (9, 15, 0.36127905571109209), (9, 16, 0.41911157414509237), (9, 17, 0.24319668004766609), (9, 18, 0.4241943391138232), (9, 19, 0.47585701450893153), (9, 20, 0.45458760886612731), (9, 21, 0.37683007511668432), (9, 22, 0.3943469876731126), (10, 0, 0.49101141981905727), (10, 1, 0.28145435588301732), (10, 2, 0.37184212240323972), (10, 3, 0.46026582989676884), (10, 4, 0.39528042488474513), (10, 5, 0.39308837318575984), (10, 6, 0.29791550212446383), (10, 7, 0.3673973629641355), (10, 8, 0.29444370643363937), (10, 9, 0.32659306639884361), (10, 10, 0.0), (10, 11, 0.35046057729691027), (10, 12, 0.32040339770051834), (10, 13, 0.29793776907084857), (10, 14, 0.58406839108544151), (10, 15, 0.44621145377024479), (10, 16, 0.55904795429254939), (10, 17, 0.44108467247470817), (10, 18, 0.34938767760374684), (10, 19, 0.46425128142712269), (10, 20, 0.24645922841553056), (10, 21, 0.41782264815153397), (10, 22, 0.35895049981356886), (11, 0, 0.60822074484477839), (11, 1, 0.34413738276731265), (11, 2, 0.45643373208628807), (11, 3, 0.39068372270973495), (11, 4, 0.4630200087555324), (11, 5, 0.29645050728184663), (11, 6, 0.37212893559836224), (11, 7, 0.50049816024021276), (11, 8, 0.4162823961612041), (11, 9, 0.44560415927888802), (11, 10, 0.35046057729691027), (11, 11, 0.0), (11, 12, 0.24055247930266882), (11, 13, 0.37399570602833843), (11, 14, 0.46117283313699825), (11, 15, 0.41960517837794387), (11, 16, 0.47086741549681538), (11, 17, 0.37552356669162634), (11, 18, 0.40930912867250474), (11, 19, 0.39687167974404858), (11, 20, 0.39769536084526425), (11, 21, 0.37087238444868226), (11, 22, 0.44539985375732771), (12, 0, 0.40516684161102456), (12, 1, 0.30992772809613028), (12, 2, 0.35833611674907895), (12, 3, 0.40190700787487155), (12, 4, 0.29654773276473523), (12, 5, 0.39270899307173501), (12, 6, 0.30641101615685129), (12, 7, 0.63903496903153123), (12, 8, 0.36896164257037822), (12, 9, 0.33587093803198598), (12, 10, 0.32040339770051834), (12, 11, 0.24055247930266882), (12, 12, 0.0), (12, 13, 0.3160876105362056), (12, 14, 0.48775423323296485), (12, 15, 0.41586594523127174), (12, 16, 0.50163076782943483), (12, 17, 0.4105847850047547), (12, 18, 0.3967842884104415), (12, 19, 0.23515491456030727), (12, 20, 0.4816049220549557), (12, 21, 0.38955711372859264), (12, 22, 0.55849792549643151), (13, 0, 0.44303672131471122), (13, 1, 0.27715326448639199), (13, 2, 0.29989380012505135), (13, 3, 0.54424460974930799), (13, 4, 0.232816329840077), (13, 5, 0.37690163248559189), (13, 6, 0.40480246851482971), (13, 7, 0.68163183619038703), (13, 8, 0.41898287280586677), (13, 9, 0.41447589888102954), (13, 10, 0.29793776907084857), (13, 11, 0.37399570602833843), (13, 12, 0.3160876105362056), (13, 13, 0.0), (13, 14, 0.49805934371900884), (13, 15, 0.40992008577214273), (13, 16, 0.54065696721743761), (13, 17, 0.38428862050888923), (13, 18, 0.4961657998896038), (13, 19, 0.44504665879242811), (13, 20, 0.38440676029203763), (13, 21, 0.46442115144679813), (13, 22, 0.52438880469629667), (14, 0, 0.4302340827337664), (14, 1, 0.49860727224071699), (14, 2, 0.5414499703223058), (14, 3, 0.50867666525308775), (14, 4, 0.50822385272597392), (14, 5, 0.4533594173035006), (14, 6, 0.45322191058983952), (14, 7, 0.59961751759143889), (14, 8, 0.57465678073217796), (14, 9, 0.4191657680715089), (14, 10, 0.58406839108544151), (14, 11, 0.46117283313699825), (14, 12, 0.48775423323296485), (14, 13, 0.49805934371900884), (14, 14, 0.0), (14, 15, 0.18741877467941637), (14, 16, 0.058249914351349671), (14, 17, 0.28532094604170377), (14, 18, 0.50705632731227646), (14, 19, 0.4994432422516909), (14, 20, 0.53363647326628005), (14, 21, 0.50223273944055136), (14, 22, 0.48204153045824571), (15, 0, 0.53153753140193538), (15, 1, 0.3627745843843298), (15, 2, 0.42475665531541756), (15, 3, 0.55003807002220451), (15, 4, 0.42701910732309922), (15, 5, 0.40728929724208518), (15, 6, 0.40275631001837409), (15, 7, 0.66179199668976285), (15, 8, 0.37077118739053427), (15, 9, 0.36127905571109209), (15, 10, 0.44621145377024479), (15, 11, 0.41960517837794387), (15, 12, 0.41586594523127174), (15, 13, 0.40992008577214273), (15, 14, 0.18741877467941637), (15, 15, 0.0), (15, 16, 0.28262653867706489), (15, 17, 0.18350887398132409), (15, 18, 0.44785132530526217), (15, 19, 0.56582895986565562), (15, 20, 0.39194507044048466), (15, 21, 0.46371547129976409), (15, 22, 0.47323699730816082), (16, 0, 0.3843143784569622), (16, 1, 0.46789453216808929), (16, 2, 0.51818690483764562), (16, 3, 0.43473692715995743), (16, 4, 0.58247591835479695), (16, 5, 0.44873428353228123), (16, 6, 0.44470808013632679), (16, 7, 0.48870168957975713), (16, 8, 0.57305098826110501), (16, 9, 0.41911157414509237), (16, 10, 0.55904795429254939), (16, 11, 0.47086741549681538), (16, 12, 0.50163076782943483), (16, 13, 0.54065696721743761), (16, 14, 0.058249914351349671), (16, 15, 0.28262653867706489), (16, 16, 0.0), (16, 17, 0.30200775044787226), (16, 18, 0.40136777349603503), (16, 19, 0.50788227104829553), (16, 20, 0.5255847380219788), (16, 21, 0.41558794026055429), (16, 22, 0.40544710560791952), (17, 0, 0.52873183935586476), (17, 1, 0.40408034067256232), (17, 2, 0.36325760912508037), (17, 3, 0.41142644218040297), (17, 4, 0.37308908188252632), (17, 5, 0.23311478850431194), (17, 6, 0.45009484677723283), (17, 7, 0.48198982460904777), (17, 8, 0.36032569480736065), (17, 9, 0.24319668004766609), (17, 10, 0.44108467247470817), (17, 11, 0.37552356669162634), (17, 12, 0.4105847850047547), (17, 13, 0.38428862050888923), (17, 14, 0.28532094604170377), (17, 15, 0.18350887398132409), (17, 16, 0.30200775044787226), (17, 17, 0.0), (17, 18, 0.2776413824772449), (17, 19, 0.53136711026695838), (17, 20, 0.29633485120649905), (17, 21, 0.22361361078136638), (17, 22, 0.33728919935760343), (18, 0, 0.49486887476451263), (18, 1, 0.44905822466934164), (18, 2, 0.47468331333386554), (18, 3, 0.51346390591116253), (18, 4, 0.55343500673824031), (18, 5, 0.38424367676342408), (18, 6, 0.44210148603326516), (18, 7, 0.43468183821851469), (18, 8, 0.46364996738422837), (18, 9, 0.4241943391138232), (18, 10, 0.34938767760374684), (18, 11, 0.40930912867250474), (18, 12, 0.3967842884104415), (18, 13, 0.4961657998896038), (18, 14, 0.50705632731227646), (18, 15, 0.44785132530526217), (18, 16, 0.40136777349603503), (18, 17, 0.2776413824772449), (18, 18, 0.0), (18, 19, 0.63327541811005672), (18, 20, 0.32623413323952), (18, 21, 0.28854031763151916), (18, 22, 0.45898925152934433), (19, 0, 0.42697360239745585), (19, 1, 0.35398731697696351), (19, 2, 0.46678797758308171), (19, 3, 0.28009056190902981), (19, 4, 0.33625254230617402), (19, 5, 0.42501264054627463), (19, 6, 0.36253077620822166), (19, 7, 0.50755456678349375), (19, 8, 0.46900464644541762), (19, 9, 0.47585701450893153), (19, 10, 0.46425128142712269), (19, 11, 0.39687167974404858), (19, 12, 0.23515491456030727), (19, 13, 0.44504665879242811), (19, 14, 0.4994432422516909), (19, 15, 0.56582895986565562), (19, 16, 0.50788227104829553), (19, 17, 0.53136711026695838), (19, 18, 0.63327541811005672), (19, 19, 0.0), (19, 20, 0.5293896941703734), (19, 21, 0.48117422355999956), (19, 22, 0.48172738664460441), (20, 0, 0.5034051653071242), (20, 1, 0.4510142081442588), (20, 2, 0.36316649176626992), (20, 3, 0.37475309620845215), (20, 4, 0.48408416705775908), (20, 5, 0.35615707483282166), (20, 6, 0.50860797384608902), (20, 7, 0.34535036897010468), (20, 8, 0.53351194845755079), (20, 9, 0.45458760886612731), (20, 10, 0.24645922841553056), (20, 11, 0.39769536084526425), (20, 12, 0.4816049220549557), (20, 13, 0.38440676029203763), (20, 14, 0.53363647326628005), (20, 15, 0.39194507044048466), (20, 16, 0.5255847380219788), (20, 17, 0.29633485120649905), (20, 18, 0.32623413323952), (20, 19, 0.5293896941703734), (20, 20, 0.0), (20, 21, 0.4501249358956409), (20, 22, 0.20278104607339206), (21, 0, 0.61456366481394875), (21, 1, 0.37327363445741185), (21, 2, 0.49987743342508789), (21, 3, 0.40949978633446504), (21, 4, 0.44674146519510682), (21, 5, 0.38559596667921958), (21, 6, 0.42152901386012731), (21, 7, 0.42532925216284351), (21, 8, 0.3624547026305675), (21, 9, 0.37683007511668432), (21, 10, 0.41782264815153397), (21, 11, 0.37087238444868226), (21, 12, 0.38955711372859264), (21, 13, 0.46442115144679813), (21, 14, 0.50223273944055136), (21, 15, 0.46371547129976409), (21, 16, 0.41558794026055429), (21, 17, 0.22361361078136638), (21, 18, 0.28854031763151916), (21, 19, 0.48117422355999956), (21, 20, 0.4501249358956409), (21, 21, 0.0), (21, 22, 0.39353143518105405), (22, 0, 0.53195399357818995), (22, 1, 0.41825332161295758), (22, 2, 0.35073571849682594), (22, 3, 0.21212554940809389), (22, 4, 0.53929876130725574), (22, 5, 0.31879576644611179), (22, 6, 0.53243745287325828), (22, 7, 0.19023768803283542), (22, 8, 0.44839013293799779), (22, 9, 0.3943469876731126), (22, 10, 0.35895049981356886), (22, 11, 0.44539985375732771), (22, 12, 0.55849792549643151), (22, 13, 0.52438880469629667), (22, 14, 0.48204153045824571), (22, 15, 0.47323699730816082), (22, 16, 0.40544710560791952), (22, 17, 0.33728919935760343), (22, 18, 0.45898925152934433), (22, 19, 0.48172738664460441), (22, 20, 0.20278104607339206), (22, 21, 0.39353143518105405), (22, 22, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "# Constructing JS Matrix\n",
    "\n",
    "# Creates a list containing 5 lists, each of 8 items, all set to 0\n",
    "w, h = 23, 23 \n",
    "Matrix = [[0 for x in range(w)] for y in range(h)] \n",
    "\n",
    "JSM = list()\n",
    "js_df = pd.DataFrame()\n",
    "\n",
    "# for index1,item1 in enumerate(doc_topic):\n",
    "#     JSM[:] = []\n",
    "#     for index2,item2 in enumerate(doc_topic):\n",
    "#         result = jsd(doc_topic[index1],doc_topic[index2])\n",
    "#         JSM.append(result)\n",
    "#         js_df = pd.DataFrame(JSM)\n",
    "#         js_df = js_df.transpose()\n",
    "#     js_df1.append(js_df)\n",
    "# #     js_df.loc[index1] = pd.DataFrame.append(JSM)\n",
    "\n",
    "# print(js_df1)\n",
    "\n",
    "# len(df.columns) = 23\n",
    "\n",
    "\n",
    "# for index1,item1 in enumerate(doc_topic):\n",
    "#     for index2,item2 in enumerate(doc_topic):\n",
    "#         result = jsd(doc_topic[index1],doc_topic[index2])\n",
    "#         js_df[index1,index2] = pd.DataFrame(result)\n",
    "        \n",
    "# print(js_df)\n",
    "\n",
    "\n",
    "for index1,item1 in enumerate(doc_topic):\n",
    "    for index2,item2 in enumerate(doc_topic):\n",
    "        result = jsd(doc_topic[index1],doc_topic[index2])\n",
    "        Matrix[index1][index2] = result\n",
    "        temp_list = list()        \n",
    "        temp_list = (index1,index2,result)\n",
    "        JSM.append(temp_list)\n",
    "\n",
    "print(JSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Writing to a txt file for Mapequation\n",
    "\n",
    "# JS_str = str(JSM)\n",
    "\n",
    "text_file = open(\"/Users/tarunruchandani/Desktop/HarvardSummer2016/mymaps/JS_output1.txt\", \"w\")\n",
    "\n",
    "for index1,item1 in enumerate(doc_topic):\n",
    "    for index2,item2 in enumerate(doc_topic):\n",
    "        result = 1-(jsd(doc_topic[index1],doc_topic[index2]))\n",
    "        text_file.write(\"%s %s %s\\n\" %(index1, index2, result))\n",
    "\n",
    "text_file.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
