{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Tarun Ruchandani (tarun.ruchandani@columbia.edu)\n",
    "Date: 2016-08-02 14:26:09 -0700 (Tue, 08 Aug 2016)\n",
    "Revision: 1\n",
    "\n",
    "Spark LDA for NASA ADS v1.0 \n",
    "\n",
    "To Do:\n",
    "x Generate document term matrix for LDA\n",
    "x Get LDA Results on small Corpus\n",
    "\n",
    "8/3:\n",
    "\n",
    "x Generate a JS Matrix per mapequation's input\n",
    "- Generate topic trend reports.\n",
    "o Build Mapequation with JS Matrix\n",
    "o Extend to a larger corpus\n",
    "o Build Docker Container\n",
    "o Deploy to adsqb\n",
    "\n",
    "- JS Matrix: figure out the right implementation - also try ifa library\n",
    "\n",
    "\n",
    "8/5:\n",
    "\n",
    "o Take care of no abstract situation\n",
    "o Scale to 500 papers\n",
    "\n",
    "8/8:\n",
    "\n",
    "o Take care of no abstract situation\n",
    "o Scale to 500 papers\n",
    "o Create a graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#All 'em libraries\n",
    "\n",
    "import numpy as np\n",
    "import textmining\n",
    "import pyspark\n",
    "import lda\n",
    "import lda.datasets\n",
    "import ads\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from numpy  import array\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarunruchandani/anaconda3/lib/python3.5/site-packages/ads/utils.py:23: UserWarning: You are lazy loading attributes via 'abstract', and so are making multiple calls to the API. This will impact your overall rate limits.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Extract Cosmology papers\n",
    "ads.config.token = 'TkEI7jQxScyoCtzHfhcpCWVelRqySmH5XBksQCFA'\n",
    "papers = list(ads.SearchQuery(q='cosmology',start=100,rows=100))\n",
    "\n",
    "paper_abstracts=list()\n",
    "\n",
    "for paper in papers:\n",
    "    paper_abstracts.append(paper.abstract)\n",
    "\n",
    "# Select first 25 papers which have abstracts. Some later ones don't. Revisit this when scaling.\n",
    "# paper_abstracts = paper_abstracts[0:25]\n",
    "print(len(paper_abstracts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build Term-Document Matrix\n",
    "\n",
    "tdm = textmining.TermDocumentMatrix()\n",
    "for paper in paper_abstracts:\n",
    "    tdm.add_doc(paper)\n",
    "    \n",
    "paper_abstracts_tdm = list()\n",
    "\n",
    "for row in tdm.rows(cutoff=0):\n",
    "    paper_abstracts_tdm.append(row)\n",
    "\n",
    "paper_abstracts_tdm_df = pd.DataFrame(paper_abstracts_tdm)\n",
    "paper_abstracts_tdm_df.head()\n",
    "\n",
    "# Vocab of terms in abstracts\n",
    "vocab = paper_abstracts_tdm_df._slice(slice(1))\n",
    "vocab\n",
    "\n",
    "d_t_freq = paper_abstracts_tdm_df._slice(slice(1,24))\n",
    "\n",
    "b=d_t_freq.values\n",
    "\n",
    "b=b.astype(int)\n",
    "\n",
    "\n",
    "# d_t_freq_m = d_t_freq.as_matrix\n",
    "# d_t_freq_np = np.ndarray(b, dtype=np.int64)\n",
    "# d_t_freq_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# running LDA on TDM\n",
    "# Parameters:\t\n",
    "# rdd – RDD of documents, which are tuples of document IDs and term (word) count vectors. \n",
    "# The term count vectors are “bags of words” with a fixed-size vocabulary \n",
    "# (where the vocabulary size is the length of the vector). Document IDs must be unique and >= 0.\n",
    "\n",
    "# k – Number of topics to infer, i.e., the number of soft cluster centers. (default: 10)\n",
    "\n",
    "# maxIterations – Maximum number of iterations allowed. (default: 20)\n",
    "\n",
    "# docConcentration – Concentration parameter (commonly named “alpha”) \n",
    "# for the prior placed on documents’ distributions over topics (“theta”). (default: -1.0)\n",
    "\n",
    "# topicConcentration – Concentration parameter (commonly named “beta” or “eta”) \n",
    "# for the prior placed on topics’ distributions over terms. (default: -1.0)\n",
    "\n",
    "# seed – Random seed for cluster initialization. Set as None to generate seed based on system time. (default: None)\n",
    "\n",
    "# checkpointInterval – Period (in iterations) between checkpoints. (default: 10)\n",
    "\n",
    "# optimizer – LDAOptimizer used to perform the actual calculation. Currently “em”, “online” are supported. \n",
    "# (default: “em”)\n",
    "\n",
    "model = lda.LDA(n_topics=20, n_iter=500, random_state=1)\n",
    "model.fit(b)\n",
    "\n",
    "topic_word = model.topic_word_  # model.components_ also works\n",
    "\n",
    "\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "     topic_words = np.array(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(doc_topic): <class 'numpy.ndarray'>\n",
      "shape: (23, 20)\n"
     ]
    }
   ],
   "source": [
    "doc_topic = model.doc_topic_\n",
    "print(\"type(doc_topic): {}\".format(type(doc_topic)))\n",
    "print(\"shape: {}\".format(doc_topic.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document: 0 sum: 1.0000000000000002\n",
      "document: 1 sum: 1.0000000000000002\n",
      "document: 2 sum: 0.9999999999999998\n",
      "document: 3 sum: 1.0\n",
      "document: 4 sum: 1.0000000000000002\n",
      "doc: 0 topic: 10\n",
      "...\n",
      "doc: 1 topic: 10\n",
      "...\n",
      "doc: 2 topic: 19\n",
      "...\n",
      "doc: 3 topic: 10\n",
      "...\n",
      "doc: 4 topic: 0\n",
      "...\n",
      "doc: 5 topic: 10\n",
      "...\n",
      "doc: 6 topic: 10\n",
      "...\n",
      "doc: 7 topic: 10\n",
      "...\n",
      "doc: 8 topic: 10\n",
      "...\n",
      "doc: 9 topic: 10\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Document-topic Probab\n",
    "\n",
    "doc_topic = model.doc_topic_\n",
    "\n",
    "for n in range(5):\n",
    "    sum_pr = sum(doc_topic[n,:])\n",
    "    print(\"document: {} sum: {}\".format(n, sum_pr))\n",
    "\n",
    "for n in range(10):\n",
    "    topic_most_pr = doc_topic[n].argmax()\n",
    "    print(\"doc: {} topic: {}\\n...\".format(n,\n",
    "                                            topic_most_pr\n",
    "                                            ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6083472859047827"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building JS Matrix\n",
    "\n",
    "\n",
    "def multi_js(p, q):\n",
    "    \"\"\"Jensen-Shannon divergence (symmetric) between two multinomials,\n",
    "    expressed in nats.\"\"\"\n",
    "    if (len(q.shape) == 2):\n",
    "        axis = 1\n",
    "    else:\n",
    "        axis = 0\n",
    "    # D_{JS}(P\\|Q) = (D_{KL}(P\\|Q) + D_{KL}(Q\\|P)) / 2\n",
    "    return 0.5 * ((q * (np.log(q.clip(1e-10,1))\n",
    "                        - np.log(p.clip(1e-10,1)))).sum(axis)\n",
    "                      + (p * (np.log(p.clip(1e-10,1))\n",
    "                              - np.log(q.clip(1e-10,1)))).sum(axis))\n",
    "\n",
    "\n",
    "JS_D1D2 = multi_js(doc_topic[0],doc_topic[1])\n",
    "JS_D1D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50076215828671167"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative JS implementation\n",
    "\n",
    "def jsd(x,y): #Jensen-shannon divergence\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", category = RuntimeWarning)\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    d1 = x*np.log2(2*x/(x+y))\n",
    "    d2 = y*np.log2(2*y/(x+y))\n",
    "    d1[np.isnan(d1)] = 0\n",
    "    d2[np.isnan(d2)] = 0\n",
    "    d = 0.5*np.sum(d1+d2)    \n",
    "    return d\n",
    "\n",
    "jsd(doc_topic[0],doc_topic[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, 0.0), (0, 1, 0.50076215828671167), (0, 2, 0.30682173101192117), (0, 3, 0.25616562094424356), (0, 4, 0.51264403759672739), (0, 5, 0.44375565799944872), (0, 6, 0.43928578679824309), (0, 7, 0.2970415237581534), (0, 8, 0.41370942231892666), (0, 9, 0.38776952176716994), (0, 10, 0.21455450561819286), (0, 11, 0.22364514180439654), (0, 12, 0.54487532939636296), (0, 13, 0.35932228130530719), (0, 14, 0.49603515064142462), (0, 15, 0.39890631533394738), (0, 16, 0.41858108927144799), (0, 17, 0.42791768746783887), (0, 18, 0.46724470175312599), (0, 19, 0.55527324527094524), (0, 20, 0.28891600806613538), (0, 21, 0.54141051551608743), (0, 22, 0.50137080319426408), (1, 0, 0.50076215828671167), (1, 1, 0.0), (1, 2, 0.54599134361791068), (1, 3, 0.53918562847616591), (1, 4, 0.44265749757005762), (1, 5, 0.48513188595832918), (1, 6, 0.41614040435137617), (1, 7, 0.40069354377120286), (1, 8, 0.39836924801447832), (1, 9, 0.39922205463606325), (1, 10, 0.47559759272512847), (1, 11, 0.47837925520591273), (1, 12, 0.1519398094744818), (1, 13, 0.49684802475925627), (1, 14, 0.39165500962406519), (1, 15, 0.4147264254537622), (1, 16, 0.48916117430011641), (1, 17, 0.32038680260817776), (1, 18, 0.34439469192482647), (1, 19, 0.49986005813767553), (1, 20, 0.34802999772842352), (1, 21, 0.24086952229087041), (1, 22, 0.32160279594862956), (2, 0, 0.30682173101192117), (2, 1, 0.54599134361791068), (2, 2, 0.0), (2, 3, 0.51226372555113009), (2, 4, 0.53115537778092747), (2, 5, 0.47963338328141125), (2, 6, 0.36944060111052157), (2, 7, 0.30556801034757208), (2, 8, 0.39936379483879492), (2, 9, 0.62283802636973762), (2, 10, 0.27339395182380305), (2, 11, 0.33543018488769061), (2, 12, 0.53216610524023811), (2, 13, 0.64392637485555027), (2, 14, 0.57255213089016121), (2, 15, 0.48609671074740723), (2, 16, 0.49542168768725758), (2, 17, 0.40719340348849853), (2, 18, 0.49007699307806607), (2, 19, 0.57808302602739925), (2, 20, 0.39228694965018551), (2, 21, 0.55058307783235116), (2, 22, 0.4550751875367996), (3, 0, 0.25616562094424356), (3, 1, 0.53918562847616591), (3, 2, 0.51226372555113009), (3, 3, 0.0), (3, 4, 0.44921554021976301), (3, 5, 0.39138967858831525), (3, 6, 0.61324626579766472), (3, 7, 0.41160413146700403), (3, 8, 0.46859661026479027), (3, 9, 0.39395024614077501), (3, 10, 0.24036928709365299), (3, 11, 0.3592977549557213), (3, 12, 0.53564039270049291), (3, 13, 0.43839292029323007), (3, 14, 0.55281722635302555), (3, 15, 0.36756813727578752), (3, 16, 0.45034928935445317), (3, 17, 0.49413884077683584), (3, 18, 0.49800517942850442), (3, 19, 0.45125263958243772), (3, 20, 0.19084953614046254), (3, 21, 0.34768871429096099), (3, 22, 0.52852145615572454), (4, 0, 0.51264403759672739), (4, 1, 0.44265749757005762), (4, 2, 0.53115537778092747), (4, 3, 0.44921554021976301), (4, 4, 0.0), (4, 5, 0.044275344099349093), (4, 6, 0.59165988732051211), (4, 7, 0.556485829967585), (4, 8, 0.54644283495473711), (4, 9, 0.32576931230859513), (4, 10, 0.37617612899775016), (4, 11, 0.52981377658082396), (4, 12, 0.4394037557340521), (4, 13, 0.52299228939944187), (4, 14, 0.52474402004843601), (4, 15, 0.34424098009471066), (4, 16, 0.59424130639990391), (4, 17, 0.580371606523577), (4, 18, 0.46801511643596311), (4, 19, 0.55354156869455473), (4, 20, 0.53827091331349464), (4, 21, 0.46070016361175675), (4, 22, 0.59093696115470296), (5, 0, 0.44375565799944872), (5, 1, 0.48513188595832918), (5, 2, 0.47963338328141125), (5, 3, 0.39138967858831525), (5, 4, 0.044275344099349093), (5, 5, 0.0), (5, 6, 0.54725990829970406), (5, 7, 0.49835315786591661), (5, 8, 0.52689798773814744), (5, 9, 0.39755235532627203), (5, 10, 0.32129001288705933), (5, 11, 0.47705887091607313), (5, 12, 0.42067539525927233), (5, 13, 0.55218013279016143), (5, 14, 0.46680788483051078), (5, 15, 0.28810079914073883), (5, 16, 0.57996200228417372), (5, 17, 0.56897431493542217), (5, 18, 0.44712670700215029), (5, 19, 0.53304547283944426), (5, 20, 0.50460670925859219), (5, 21, 0.45495636125269567), (5, 22, 0.56745348002234564), (6, 0, 0.43928578679824309), (6, 1, 0.41614040435137617), (6, 2, 0.36944060111052157), (6, 3, 0.61324626579766472), (6, 4, 0.59165988732051211), (6, 5, 0.54725990829970406), (6, 6, 0.0), (6, 7, 0.35876566398884885), (6, 8, 0.42151952371509693), (6, 9, 0.53720647163806867), (6, 10, 0.49118228009272114), (6, 11, 0.40745145731251065), (6, 12, 0.36738490210308117), (6, 13, 0.53225824658422438), (6, 14, 0.53698160486462432), (6, 15, 0.49559542432653136), (6, 16, 0.57274006909757258), (6, 17, 0.52030511363893417), (6, 18, 0.37765487479273019), (6, 19, 0.4688891510481959), (6, 20, 0.5627497585710789), (6, 21, 0.42639255944417026), (6, 22, 0.40206968030806989), (7, 0, 0.2970415237581534), (7, 1, 0.40069354377120286), (7, 2, 0.30556801034757208), (7, 3, 0.41160413146700403), (7, 4, 0.556485829967585), (7, 5, 0.49835315786591661), (7, 6, 0.35876566398884885), (7, 7, 0.0), (7, 8, 0.36930176123023201), (7, 9, 0.47872886185911234), (7, 10, 0.40456079434279318), (7, 11, 0.15496250064721165), (7, 12, 0.44109933435512488), (7, 13, 0.27541713922686772), (7, 14, 0.49070547327203151), (7, 15, 0.45917332976228475), (7, 16, 0.33925958655654326), (7, 17, 0.4580414828858082), (7, 18, 0.44176557796056143), (7, 19, 0.45510607157855199), (7, 20, 0.41796727747172746), (7, 21, 0.48872044688428162), (7, 22, 0.42320670716056158), (8, 0, 0.41370942231892666), (8, 1, 0.39836924801447832), (8, 2, 0.39936379483879492), (8, 3, 0.46859661026479027), (8, 4, 0.54644283495473711), (8, 5, 0.52689798773814744), (8, 6, 0.42151952371509693), (8, 7, 0.36930176123023201), (8, 8, 0.0), (8, 9, 0.53812003845862044), (8, 10, 0.35130491618104348), (8, 11, 0.42514662128691211), (8, 12, 0.40638045678549173), (8, 13, 0.3498728143640894), (8, 14, 0.47711311153517283), (8, 15, 0.50481293461912546), (8, 16, 0.51542221463983751), (8, 17, 0.51074920774636723), (8, 18, 0.43778124655359651), (8, 19, 0.4848184761437746), (8, 20, 0.38003184472133239), (8, 21, 0.33780508839244072), (8, 22, 0.42225608227207456), (9, 0, 0.38776952176716994), (9, 1, 0.39922205463606325), (9, 2, 0.62283802636973762), (9, 3, 0.39395024614077501), (9, 4, 0.32576931230859513), (9, 5, 0.39755235532627203), (9, 6, 0.53720647163806867), (9, 7, 0.47872886185911234), (9, 8, 0.53812003845862044), (9, 9, 0.0), (9, 10, 0.54139432414096522), (9, 11, 0.47855461016024547), (9, 12, 0.49207910518042436), (9, 13, 0.35077666696054383), (9, 14, 0.52173114801197007), (9, 15, 0.38571549998360066), (9, 16, 0.58067075930507783), (9, 17, 0.53025611733074851), (9, 18, 0.43078000810500677), (9, 19, 0.48912001316567544), (9, 20, 0.4897981964118972), (9, 21, 0.4942213277172916), (9, 22, 0.60690388624775682), (10, 0, 0.21455450561819286), (10, 1, 0.47559759272512847), (10, 2, 0.27339395182380305), (10, 3, 0.24036928709365299), (10, 4, 0.37617612899775016), (10, 5, 0.32129001288705933), (10, 6, 0.49118228009272114), (10, 7, 0.40456079434279318), (10, 8, 0.35130491618104348), (10, 9, 0.54139432414096522), (10, 10, 0.0), (10, 11, 0.30938221553779943), (10, 12, 0.42964260384360886), (10, 13, 0.41418230244251558), (10, 14, 0.49086299012314771), (10, 15, 0.46453466474570082), (10, 16, 0.43104258490278891), (10, 17, 0.42157509247164215), (10, 18, 0.43216785756240406), (10, 19, 0.41443028430918916), (10, 20, 0.25106134201544439), (10, 21, 0.35687036400632988), (10, 22, 0.40679699922729179), (11, 0, 0.22364514180439654), (11, 1, 0.47837925520591273), (11, 2, 0.33543018488769061), (11, 3, 0.3592977549557213), (11, 4, 0.52981377658082396), (11, 5, 0.47705887091607313), (11, 6, 0.40745145731251065), (11, 7, 0.15496250064721165), (11, 8, 0.42514662128691211), (11, 9, 0.47855461016024547), (11, 10, 0.30938221553779943), (11, 11, 0.0), (11, 12, 0.50678728076018242), (11, 13, 0.32162406754707384), (11, 14, 0.50451804499338226), (11, 15, 0.5457262225865146), (11, 16, 0.18128456387667635), (11, 17, 0.44587544053961037), (11, 18, 0.37285709184499066), (11, 19, 0.41003809751027442), (11, 20, 0.37033504269325607), (11, 21, 0.47307860368855331), (11, 22, 0.33504007482819659), (12, 0, 0.54487532939636296), (12, 1, 0.1519398094744818), (12, 2, 0.53216610524023811), (12, 3, 0.53564039270049291), (12, 4, 0.4394037557340521), (12, 5, 0.42067539525927233), (12, 6, 0.36738490210308117), (12, 7, 0.44109933435512488), (12, 8, 0.40638045678549173), (12, 9, 0.49207910518042436), (12, 10, 0.42964260384360886), (12, 11, 0.50678728076018242), (12, 12, 0.0), (12, 13, 0.53475285272332318), (12, 14, 0.34122818911249009), (12, 15, 0.41242707617626301), (12, 16, 0.55279199247621769), (12, 17, 0.22690771427613096), (12, 18, 0.33109180447264286), (12, 19, 0.41758501107824225), (12, 20, 0.31898624867849923), (12, 21, 0.26014502162865527), (12, 22, 0.1857775666910601), (13, 0, 0.35932228130530719), (13, 1, 0.49684802475925627), (13, 2, 0.64392637485555027), (13, 3, 0.43839292029323007), (13, 4, 0.52299228939944187), (13, 5, 0.55218013279016143), (13, 6, 0.53225824658422438), (13, 7, 0.27541713922686772), (13, 8, 0.3498728143640894), (13, 9, 0.35077666696054383), (13, 10, 0.41418230244251558), (13, 11, 0.32162406754707384), (13, 12, 0.53475285272332318), (13, 13, 0.0), (13, 14, 0.57280029840478996), (13, 15, 0.61536686854480493), (13, 16, 0.43822202651169095), (13, 17, 0.59204415149873246), (13, 18, 0.53850819873143718), (13, 19, 0.46025518666962156), (13, 20, 0.55193887774963879), (13, 21, 0.5205128624136085), (13, 22, 0.59344060696405032), (14, 0, 0.49603515064142462), (14, 1, 0.39165500962406519), (14, 2, 0.57255213089016121), (14, 3, 0.55281722635302555), (14, 4, 0.52474402004843601), (14, 5, 0.46680788483051078), (14, 6, 0.53698160486462432), (14, 7, 0.49070547327203151), (14, 8, 0.47711311153517283), (14, 9, 0.52173114801197007), (14, 10, 0.49086299012314771), (14, 11, 0.50451804499338226), (14, 12, 0.34122818911249009), (14, 13, 0.57280029840478996), (14, 14, 0.0), (14, 15, 0.46193247431153694), (14, 16, 0.5472777509653054), (14, 17, 0.54137286169345566), (14, 18, 0.44852311991950267), (14, 19, 0.54612591995486082), (14, 20, 0.48842957871376391), (14, 21, 0.4451233504516684), (14, 22, 0.46239144824155742), (15, 0, 0.39890631533394738), (15, 1, 0.4147264254537622), (15, 2, 0.48609671074740723), (15, 3, 0.36756813727578752), (15, 4, 0.34424098009471066), (15, 5, 0.28810079914073883), (15, 6, 0.49559542432653136), (15, 7, 0.45917332976228475), (15, 8, 0.50481293461912546), (15, 9, 0.38571549998360066), (15, 10, 0.46453466474570082), (15, 11, 0.5457262225865146), (15, 12, 0.41242707617626301), (15, 13, 0.61536686854480493), (15, 14, 0.46193247431153694), (15, 15, 0.0), (15, 16, 0.63238837277712667), (15, 17, 0.58556652064593129), (15, 18, 0.38506350909710141), (15, 19, 0.63023072339204289), (15, 20, 0.35945919438209356), (15, 21, 0.44404009220413965), (15, 22, 0.52418279697371051), (16, 0, 0.41858108927144799), (16, 1, 0.48916117430011641), (16, 2, 0.49542168768725758), (16, 3, 0.45034928935445317), (16, 4, 0.59424130639990391), (16, 5, 0.57996200228417372), (16, 6, 0.57274006909757258), (16, 7, 0.33925958655654326), (16, 8, 0.51542221463983751), (16, 9, 0.58067075930507783), (16, 10, 0.43104258490278891), (16, 11, 0.18128456387667635), (16, 12, 0.55279199247621769), (16, 13, 0.43822202651169095), (16, 14, 0.5472777509653054), (16, 15, 0.63238837277712667), (16, 16, 0.0), (16, 17, 0.4750571036416894), (16, 18, 0.25412622714499788), (16, 19, 0.43238104616787154), (16, 20, 0.40785769790825205), (16, 21, 0.53045605460124889), (16, 22, 0.47813874726808286), (17, 0, 0.42791768746783887), (17, 1, 0.32038680260817776), (17, 2, 0.40719340348849853), (17, 3, 0.49413884077683584), (17, 4, 0.580371606523577), (17, 5, 0.56897431493542217), (17, 6, 0.52030511363893417), (17, 7, 0.4580414828858082), (17, 8, 0.51074920774636723), (17, 9, 0.53025611733074851), (17, 10, 0.42157509247164215), (17, 11, 0.44587544053961037), (17, 12, 0.22690771427613096), (17, 13, 0.59204415149873246), (17, 14, 0.54137286169345566), (17, 15, 0.58556652064593129), (17, 16, 0.4750571036416894), (17, 17, 0.0), (17, 18, 0.44696215611951767), (17, 19, 0.52380862772948622), (17, 20, 0.23876848035841686), (17, 21, 0.43377268767072852), (17, 22, 0.24418744892229988), (18, 0, 0.46724470175312599), (18, 1, 0.34439469192482647), (18, 2, 0.49007699307806607), (18, 3, 0.49800517942850442), (18, 4, 0.46801511643596311), (18, 5, 0.44712670700215029), (18, 6, 0.37765487479273019), (18, 7, 0.44176557796056143), (18, 8, 0.43778124655359651), (18, 9, 0.43078000810500677), (18, 10, 0.43216785756240406), (18, 11, 0.37285709184499066), (18, 12, 0.33109180447264286), (18, 13, 0.53850819873143718), (18, 14, 0.44852311991950267), (18, 15, 0.38506350909710141), (18, 16, 0.25412622714499788), (18, 17, 0.44696215611951767), (18, 18, 0.0), (18, 19, 0.33677928661039414), (18, 20, 0.35949192753224612), (18, 21, 0.33372878637185011), (18, 22, 0.41018890500143507), (19, 0, 0.55527324527094524), (19, 1, 0.49986005813767553), (19, 2, 0.57808302602739925), (19, 3, 0.45125263958243772), (19, 4, 0.55354156869455473), (19, 5, 0.53304547283944426), (19, 6, 0.4688891510481959), (19, 7, 0.45510607157855199), (19, 8, 0.4848184761437746), (19, 9, 0.48912001316567544), (19, 10, 0.41443028430918916), (19, 11, 0.41003809751027442), (19, 12, 0.41758501107824225), (19, 13, 0.46025518666962156), (19, 14, 0.54612591995486082), (19, 15, 0.63023072339204289), (19, 16, 0.43238104616787154), (19, 17, 0.52380862772948622), (19, 18, 0.33677928661039414), (19, 19, 0.0), (19, 20, 0.46257724783401077), (19, 21, 0.36622108543372978), (19, 22, 0.43244437970509841), (20, 0, 0.28891600806613538), (20, 1, 0.34802999772842352), (20, 2, 0.39228694965018551), (20, 3, 0.19084953614046254), (20, 4, 0.53827091331349464), (20, 5, 0.50460670925859219), (20, 6, 0.5627497585710789), (20, 7, 0.41796727747172746), (20, 8, 0.38003184472133239), (20, 9, 0.4897981964118972), (20, 10, 0.25106134201544439), (20, 11, 0.37033504269325607), (20, 12, 0.31898624867849923), (20, 13, 0.55193887774963879), (20, 14, 0.48842957871376391), (20, 15, 0.35945919438209356), (20, 16, 0.40785769790825205), (20, 17, 0.23876848035841686), (20, 18, 0.35949192753224612), (20, 19, 0.46257724783401077), (20, 20, 0.0), (20, 21, 0.26920454237024122), (20, 22, 0.2925555202619784), (21, 0, 0.54141051551608743), (21, 1, 0.24086952229087041), (21, 2, 0.55058307783235116), (21, 3, 0.34768871429096099), (21, 4, 0.46070016361175675), (21, 5, 0.45495636125269567), (21, 6, 0.42639255944417026), (21, 7, 0.48872044688428162), (21, 8, 0.33780508839244072), (21, 9, 0.4942213277172916), (21, 10, 0.35687036400632988), (21, 11, 0.47307860368855331), (21, 12, 0.26014502162865527), (21, 13, 0.5205128624136085), (21, 14, 0.4451233504516684), (21, 15, 0.44404009220413965), (21, 16, 0.53045605460124889), (21, 17, 0.43377268767072852), (21, 18, 0.33372878637185011), (21, 19, 0.36622108543372978), (21, 20, 0.26920454237024122), (21, 21, 0.0), (21, 22, 0.30514338227367466), (22, 0, 0.50137080319426408), (22, 1, 0.32160279594862956), (22, 2, 0.4550751875367996), (22, 3, 0.52852145615572454), (22, 4, 0.59093696115470296), (22, 5, 0.56745348002234564), (22, 6, 0.40206968030806989), (22, 7, 0.42320670716056158), (22, 8, 0.42225608227207456), (22, 9, 0.60690388624775682), (22, 10, 0.40679699922729179), (22, 11, 0.33504007482819659), (22, 12, 0.1857775666910601), (22, 13, 0.59344060696405032), (22, 14, 0.46239144824155742), (22, 15, 0.52418279697371051), (22, 16, 0.47813874726808286), (22, 17, 0.24418744892229988), (22, 18, 0.41018890500143507), (22, 19, 0.43244437970509841), (22, 20, 0.2925555202619784), (22, 21, 0.30514338227367466), (22, 22, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "# Constructing JS Matrix\n",
    "\n",
    "# Creates a list containing 5 lists, each of 8 items, all set to 0\n",
    "w, h = 23, 23 \n",
    "Matrix = [[0 for x in range(w)] for y in range(h)] \n",
    "\n",
    "JSM = list()\n",
    "js_df = pd.DataFrame()\n",
    "\n",
    "# for index1,item1 in enumerate(doc_topic):\n",
    "#     JSM[:] = []\n",
    "#     for index2,item2 in enumerate(doc_topic):\n",
    "#         result = jsd(doc_topic[index1],doc_topic[index2])\n",
    "#         JSM.append(result)\n",
    "#         js_df = pd.DataFrame(JSM)\n",
    "#         js_df = js_df.transpose()\n",
    "#     js_df1.append(js_df)\n",
    "# #     js_df.loc[index1] = pd.DataFrame.append(JSM)\n",
    "\n",
    "# print(js_df1)\n",
    "\n",
    "# len(df.columns) = 23\n",
    "\n",
    "\n",
    "# for index1,item1 in enumerate(doc_topic):\n",
    "#     for index2,item2 in enumerate(doc_topic):\n",
    "#         result = jsd(doc_topic[index1],doc_topic[index2])\n",
    "#         js_df[index1,index2] = pd.DataFrame(result)\n",
    "        \n",
    "# print(js_df)\n",
    "\n",
    "\n",
    "for index1,item1 in enumerate(doc_topic):\n",
    "    for index2,item2 in enumerate(doc_topic):\n",
    "        result = jsd(doc_topic[index1],doc_topic[index2])\n",
    "        Matrix[index1][index2] = result\n",
    "        temp_list = list()        \n",
    "        temp_list = (index1,index2,result)\n",
    "        JSM.append(temp_list)\n",
    "\n",
    "print(JSM)\n",
    "\n",
    "text_file3 = open(\"/Users/tarunruchandani/Desktop/HarvardSummer2016/Infomap/JS_output3.txt\", \"w\")\n",
    "text_file3.write(str(JSM))\n",
    "text_file3.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Writing to a txt file for Mapequation\n",
    "\n",
    "# JS_str = str(JSM)\n",
    "\n",
    "text_file = open(\"/Users/tarunruchandani/Desktop/HarvardSummer2016/Infomap/JS_output2.txt\", \"w\")\n",
    "\n",
    "for index1,item1 in enumerate(doc_topic):\n",
    "    for index2,item2 in enumerate(doc_topic):\n",
    "        result = 1-(jsd(doc_topic[index1],doc_topic[index2]))\n",
    "        text_file.write(\"%s %s %s\\n\" %(index1, index2, result))\n",
    "\n",
    "text_file.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "G=nx.Graph()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
