{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark LDA for NASA ADS v1.0 \n",
    "8/2/2016\n",
    "@author: Tarun Ruchandani\n",
    "\n",
    "To Do:\n",
    "x Generate document term matrix for LDA\n",
    "x Get LDA Results on small Corpus\n",
    "\n",
    "o Generate JS Matrix: figure out the right implementation - also try ifa library\n",
    "o Build Mapequation with JS Matrix\n",
    "o Extend to a larger corpus\n",
    "o Build Docker Container\n",
    "o Deploy to adsqb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#All 'em libraries\n",
    "\n",
    "import numpy as np\n",
    "import textmining\n",
    "import pyspark\n",
    "import lda\n",
    "import lda.datasets\n",
    "import ads\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from numpy  import array\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarunruchandani/anaconda3/lib/python3.5/site-packages/ads/utils.py:23: UserWarning: You are lazy loading attributes via 'abstract', and so are making multiple calls to the API. This will impact your overall rate limits.\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "# Extract Cosmology papers\n",
    "ads.config.token = 'TkEI7jQxScyoCtzHfhcpCWVelRqySmH5XBksQCFA'\n",
    "papers = list(ads.SearchQuery(q='cosmology'))\n",
    "\n",
    "paper_abstracts=list()\n",
    "\n",
    "for paper in papers:\n",
    "    paper_abstracts.append(paper.abstract)\n",
    "\n",
    "# Select first 25 papers which have abstracts. Some later ones don't. Revisit this when scaling.\n",
    "paper_abstracts = paper_abstracts[0:25]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build Term-Document Matrix\n",
    "\n",
    "tdm = textmining.TermDocumentMatrix()\n",
    "for paper in paper_abstracts:\n",
    "    tdm.add_doc(paper)\n",
    "    \n",
    "paper_abstracts_tdm = list()\n",
    "\n",
    "for row in tdm.rows(cutoff=0):\n",
    "    paper_abstracts_tdm.append(row)\n",
    "\n",
    "paper_abstracts_tdm_df = pd.DataFrame(paper_abstracts_tdm)\n",
    "paper_abstracts_tdm_df.head()\n",
    "\n",
    "# Vocab of terms in abstracts\n",
    "vocab = paper_abstracts_tdm_df._slice(slice(1))\n",
    "vocab\n",
    "\n",
    "d_t_freq = paper_abstracts_tdm_df._slice(slice(1,24))\n",
    "\n",
    "b=d_t_freq.values\n",
    "\n",
    "b=b.astype(int)\n",
    "\n",
    "\n",
    "# d_t_freq_m = d_t_freq.as_matrix\n",
    "# d_t_freq_np = np.ndarray(b, dtype=np.int64)\n",
    "# d_t_freq_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# running LDA on TDM\n",
    "# Parameters:\t\n",
    "# rdd – RDD of documents, which are tuples of document IDs and term (word) count vectors. \n",
    "# The term count vectors are “bags of words” with a fixed-size vocabulary \n",
    "# (where the vocabulary size is the length of the vector). Document IDs must be unique and >= 0.\n",
    "\n",
    "# k – Number of topics to infer, i.e., the number of soft cluster centers. (default: 10)\n",
    "\n",
    "# maxIterations – Maximum number of iterations allowed. (default: 20)\n",
    "\n",
    "# docConcentration – Concentration parameter (commonly named “alpha”) \n",
    "# for the prior placed on documents’ distributions over topics (“theta”). (default: -1.0)\n",
    "\n",
    "# topicConcentration – Concentration parameter (commonly named “beta” or “eta”) \n",
    "# for the prior placed on topics’ distributions over terms. (default: -1.0)\n",
    "\n",
    "# seed – Random seed for cluster initialization. Set as None to generate seed based on system time. (default: None)\n",
    "\n",
    "# checkpointInterval – Period (in iterations) between checkpoints. (default: 10)\n",
    "\n",
    "# optimizer – LDAOptimizer used to perform the actual calculation. Currently “em”, “online” are supported. \n",
    "# (default: “em”)\n",
    "\n",
    "model = lda.LDA(n_topics=20, n_iter=500, random_state=1)\n",
    "model.fit(b)\n",
    "\n",
    "topic_word = model.topic_word_  # model.components_ also works\n",
    "\n",
    "\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "     topic_words = np.array(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(doc_topic): <class 'numpy.ndarray'>\n",
      "shape: (23, 20)\n"
     ]
    }
   ],
   "source": [
    "doc_topic = model.doc_topic_\n",
    "print(\"type(doc_topic): {}\".format(type(doc_topic)))\n",
    "print(\"shape: {}\".format(doc_topic.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document: 0 sum: 0.9999999999999998\n",
      "document: 1 sum: 1.0\n",
      "document: 2 sum: 1.0000000000000002\n",
      "document: 3 sum: 0.9999999999999999\n",
      "document: 4 sum: 0.9999999999999998\n",
      "doc: 0 topic: 12\n",
      "...\n",
      "doc: 1 topic: 14\n",
      "...\n",
      "doc: 2 topic: 10\n",
      "...\n",
      "doc: 3 topic: 16\n",
      "...\n",
      "doc: 4 topic: 14\n",
      "...\n",
      "doc: 5 topic: 16\n",
      "...\n",
      "doc: 6 topic: 14\n",
      "...\n",
      "doc: 7 topic: 17\n",
      "...\n",
      "doc: 8 topic: 14\n",
      "...\n",
      "doc: 9 topic: 14\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Document-topic Probab\n",
    "\n",
    "doc_topic = model.doc_topic_\n",
    "\n",
    "for n in range(5):\n",
    "    sum_pr = sum(doc_topic[n,:])\n",
    "    print(\"document: {} sum: {}\".format(n, sum_pr))\n",
    "\n",
    "for n in range(10):\n",
    "    topic_most_pr = doc_topic[n].argmax()\n",
    "    print(\"doc: {} topic: {}\\n...\".format(n,\n",
    "                                            topic_most_pr\n",
    "                                            ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.87007848208287"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building JS Matrix\n",
    "\n",
    "\n",
    "def multi_js(p, q):\n",
    "    \"\"\"Jensen-Shannon divergence (symmetric) between two multinomials,\n",
    "    expressed in nats.\"\"\"\n",
    "    if (len(q.shape) == 2):\n",
    "        axis = 1\n",
    "    else:\n",
    "        axis = 0\n",
    "    # D_{JS}(P\\|Q) = (D_{KL}(P\\|Q) + D_{KL}(Q\\|P)) / 2\n",
    "    return 0.5 * ((q * (np.log(q.clip(1e-10,1))\n",
    "                        - np.log(p.clip(1e-10,1)))).sum(axis)\n",
    "                      + (p * (np.log(p.clip(1e-10,1))\n",
    "                              - np.log(q.clip(1e-10,1)))).sum(axis))\n",
    "\n",
    "\n",
    "JS_D1D2 = multi_js(doc_topic[0],doc_topic[1])\n",
    "JS_D1D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58639318010578223"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative JS implementation\n",
    "\n",
    "def jsd(x,y): #Jensen-shannon divergence\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", category = RuntimeWarning)\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    d1 = x*np.log2(2*x/(x+y))\n",
    "    d2 = y*np.log2(2*y/(x+y))\n",
    "    d1[np.isnan(d1)] = 0\n",
    "    d2[np.isnan(d2)] = 0\n",
    "    d = 0.5*np.sum(d1+d2)    \n",
    "    return d\n",
    "\n",
    "jsd(doc_topic[0],doc_topic[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0         1         2         3         4         5         6         7    \\\n",
      "0  0.0  0.586393  0.571829  0.651409  0.493998  0.518462  0.475741  0.455646   \n",
      "\n",
      "        8         9   ...        519       520       521       522       523  \\\n",
      "0  0.561006  0.349864 ...   0.407603  0.434972  0.656174  0.599095  0.500193   \n",
      "\n",
      "        524       525       526       527  528  \n",
      "0  0.422044  0.407688  0.571135  0.562574  0.0  \n",
      "\n",
      "[1 rows x 529 columns]\n"
     ]
    }
   ],
   "source": [
    "# Constructing JS Matrix\n",
    "\n",
    "JSM = list()\n",
    "for index1,item1 in enumerate(doc_topic):\n",
    "    for index2,item2 in enumerate(doc_topic):\n",
    "        result = jsd(doc_topic[index1],doc_topic[index2])\n",
    "        JSM.append(result)\n",
    "    js_df = pd.DataFrame(JSM)\n",
    "    js_df = js_df.transpose()\n",
    "    js_df[index1] = js_df\n",
    "\n",
    "print(js_df)\n",
    "\n",
    "\n",
    "# for index1,item1 in enumerate(doc_topic):\n",
    "#     for index2,item2 in enumerate(doc_topic):\n",
    "#         result = jsd(doc_topic[index1],doc_topic[index2])\n",
    "#         js_df[index1,index2] = pd.DataFrame(result)\n",
    "        \n",
    "# print(js_df)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
