{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark LDA for NASA ADS v1.0 \n",
    "8/2/2016\n",
    "@author: Tarun Ruchandani\n",
    "\n",
    "To Do:\n",
    "x Generate document term matrix for LDA\n",
    "x Get LDA Results on small Corpus\n",
    "\n",
    "8/3:\n",
    "\n",
    "o Generate a JS Matrix per mapequation's input\n",
    "- Generate topic trend reports.\n",
    "o Build Mapequation with JS Matrix\n",
    "o Extend to a larger corpus\n",
    "o Build Docker Container\n",
    "o Deploy to adsqb\n",
    "\n",
    "- JS Matrix: figure out the right implementation - also try ifa library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#All 'em libraries\n",
    "\n",
    "import numpy as np\n",
    "import textmining\n",
    "import pyspark\n",
    "import lda\n",
    "import lda.datasets\n",
    "import ads\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from numpy  import array\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarunruchandani/anaconda3/lib/python3.5/site-packages/ads/utils.py:23: UserWarning: You are lazy loading attributes via 'abstract', and so are making multiple calls to the API. This will impact your overall rate limits.\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "# Extract Cosmology papers\n",
    "ads.config.token = 'TkEI7jQxScyoCtzHfhcpCWVelRqySmH5XBksQCFA'\n",
    "papers = list(ads.SearchQuery(q='cosmology'))\n",
    "\n",
    "paper_abstracts=list()\n",
    "\n",
    "for paper in papers:\n",
    "    paper_abstracts.append(paper.abstract)\n",
    "\n",
    "# Select first 25 papers which have abstracts. Some later ones don't. Revisit this when scaling.\n",
    "paper_abstracts = paper_abstracts[0:25]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build Term-Document Matrix\n",
    "\n",
    "tdm = textmining.TermDocumentMatrix()\n",
    "for paper in paper_abstracts:\n",
    "    tdm.add_doc(paper)\n",
    "    \n",
    "paper_abstracts_tdm = list()\n",
    "\n",
    "for row in tdm.rows(cutoff=0):\n",
    "    paper_abstracts_tdm.append(row)\n",
    "\n",
    "paper_abstracts_tdm_df = pd.DataFrame(paper_abstracts_tdm)\n",
    "paper_abstracts_tdm_df.head()\n",
    "\n",
    "# Vocab of terms in abstracts\n",
    "vocab = paper_abstracts_tdm_df._slice(slice(1))\n",
    "vocab\n",
    "\n",
    "d_t_freq = paper_abstracts_tdm_df._slice(slice(1,24))\n",
    "\n",
    "b=d_t_freq.values\n",
    "\n",
    "b=b.astype(int)\n",
    "\n",
    "\n",
    "# d_t_freq_m = d_t_freq.as_matrix\n",
    "# d_t_freq_np = np.ndarray(b, dtype=np.int64)\n",
    "# d_t_freq_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# running LDA on TDM\n",
    "# Parameters:\t\n",
    "# rdd – RDD of documents, which are tuples of document IDs and term (word) count vectors. \n",
    "# The term count vectors are “bags of words” with a fixed-size vocabulary \n",
    "# (where the vocabulary size is the length of the vector). Document IDs must be unique and >= 0.\n",
    "\n",
    "# k – Number of topics to infer, i.e., the number of soft cluster centers. (default: 10)\n",
    "\n",
    "# maxIterations – Maximum number of iterations allowed. (default: 20)\n",
    "\n",
    "# docConcentration – Concentration parameter (commonly named “alpha”) \n",
    "# for the prior placed on documents’ distributions over topics (“theta”). (default: -1.0)\n",
    "\n",
    "# topicConcentration – Concentration parameter (commonly named “beta” or “eta”) \n",
    "# for the prior placed on topics’ distributions over terms. (default: -1.0)\n",
    "\n",
    "# seed – Random seed for cluster initialization. Set as None to generate seed based on system time. (default: None)\n",
    "\n",
    "# checkpointInterval – Period (in iterations) between checkpoints. (default: 10)\n",
    "\n",
    "# optimizer – LDAOptimizer used to perform the actual calculation. Currently “em”, “online” are supported. \n",
    "# (default: “em”)\n",
    "\n",
    "model = lda.LDA(n_topics=20, n_iter=500, random_state=1)\n",
    "model.fit(b)\n",
    "\n",
    "topic_word = model.topic_word_  # model.components_ also works\n",
    "\n",
    "\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "     topic_words = np.array(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(doc_topic): <class 'numpy.ndarray'>\n",
      "shape: (23, 20)\n"
     ]
    }
   ],
   "source": [
    "doc_topic = model.doc_topic_\n",
    "print(\"type(doc_topic): {}\".format(type(doc_topic)))\n",
    "print(\"shape: {}\".format(doc_topic.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document: 0 sum: 0.9999999999999998\n",
      "document: 1 sum: 1.0\n",
      "document: 2 sum: 1.0000000000000002\n",
      "document: 3 sum: 0.9999999999999999\n",
      "document: 4 sum: 0.9999999999999998\n",
      "doc: 0 topic: 12\n",
      "...\n",
      "doc: 1 topic: 14\n",
      "...\n",
      "doc: 2 topic: 10\n",
      "...\n",
      "doc: 3 topic: 16\n",
      "...\n",
      "doc: 4 topic: 14\n",
      "...\n",
      "doc: 5 topic: 16\n",
      "...\n",
      "doc: 6 topic: 14\n",
      "...\n",
      "doc: 7 topic: 17\n",
      "...\n",
      "doc: 8 topic: 14\n",
      "...\n",
      "doc: 9 topic: 14\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Document-topic Probab\n",
    "\n",
    "doc_topic = model.doc_topic_\n",
    "\n",
    "for n in range(5):\n",
    "    sum_pr = sum(doc_topic[n,:])\n",
    "    print(\"document: {} sum: {}\".format(n, sum_pr))\n",
    "\n",
    "for n in range(10):\n",
    "    topic_most_pr = doc_topic[n].argmax()\n",
    "    print(\"doc: {} topic: {}\\n...\".format(n,\n",
    "                                            topic_most_pr\n",
    "                                            ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.87007848208287"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building JS Matrix\n",
    "\n",
    "\n",
    "def multi_js(p, q):\n",
    "    \"\"\"Jensen-Shannon divergence (symmetric) between two multinomials,\n",
    "    expressed in nats.\"\"\"\n",
    "    if (len(q.shape) == 2):\n",
    "        axis = 1\n",
    "    else:\n",
    "        axis = 0\n",
    "    # D_{JS}(P\\|Q) = (D_{KL}(P\\|Q) + D_{KL}(Q\\|P)) / 2\n",
    "    return 0.5 * ((q * (np.log(q.clip(1e-10,1))\n",
    "                        - np.log(p.clip(1e-10,1)))).sum(axis)\n",
    "                      + (p * (np.log(p.clip(1e-10,1))\n",
    "                              - np.log(q.clip(1e-10,1)))).sum(axis))\n",
    "\n",
    "\n",
    "JS_D1D2 = multi_js(doc_topic[0],doc_topic[1])\n",
    "JS_D1D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58639318010578223"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative JS implementation\n",
    "\n",
    "def jsd(x,y): #Jensen-shannon divergence\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", category = RuntimeWarning)\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    d1 = x*np.log2(2*x/(x+y))\n",
    "    d2 = y*np.log2(2*y/(x+y))\n",
    "    d1[np.isnan(d1)] = 0\n",
    "    d2[np.isnan(d2)] = 0\n",
    "    d = 0.5*np.sum(d1+d2)    \n",
    "    return d\n",
    "\n",
    "jsd(doc_topic[0],doc_topic[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, 0.0), (0, 1, 0.58639318010578223), (0, 2, 0.57182932127774189), (0, 3, 0.65140890578611887), (0, 4, 0.49399775280398323), (0, 5, 0.51846183726580952), (0, 6, 0.47574099780208245), (0, 7, 0.45564591065379617), (0, 8, 0.56100569446174875), (0, 9, 0.34986372615036193), (0, 10, 0.51628707009756458), (0, 11, 0.52973107702094779), (0, 12, 0.53890227211158004), (0, 13, 0.5146657333157868), (0, 14, 0.49736924475057098), (0, 15, 0.58248789556331948), (0, 16, 0.6776139772034957), (0, 17, 0.52597275949718791), (0, 18, 0.71594709571336135), (0, 19, 0.42486033117478794), (0, 20, 0.64032603774521635), (0, 21, 0.47914415732892879), (0, 22, 0.39969541644011874), (1, 0, 0.58639318010578223), (1, 1, 0.0), (1, 2, 0.38249746079496416), (1, 3, 0.47971625272104002), (1, 4, 0.14674814750185905), (1, 5, 0.35317581653481867), (1, 6, 0.39650503469487058), (1, 7, 0.52498495931975242), (1, 8, 0.33556985142610146), (1, 9, 0.42326318887780884), (1, 10, 0.25170210849813784), (1, 11, 0.50786656419891174), (1, 12, 0.38777266026135659), (1, 13, 0.25692128786469992), (1, 14, 0.33276004667472148), (1, 15, 0.68471966667506567), (1, 16, 0.41580975061245135), (1, 17, 0.62937213092971744), (1, 18, 0.5025238787123274), (1, 19, 0.53638794936262513), (1, 20, 0.4018784228699489), (1, 21, 0.61038742489197018), (1, 22, 0.39371461198239027), (2, 0, 0.57182932127774189), (2, 1, 0.38249746079496416), (2, 2, 0.0), (2, 3, 0.52443668623073392), (2, 4, 0.35203352985456088), (2, 5, 0.37541175389780568), (2, 6, 0.42325418386701646), (2, 7, 0.49418419346336528), (2, 8, 0.34194362384899329), (2, 9, 0.35332656616677754), (2, 10, 0.28002333450382305), (2, 11, 0.54365357049699736), (2, 12, 0.51639393870232375), (2, 13, 0.43429166784441947), (2, 14, 0.29338742478788299), (2, 15, 0.75754074934714755), (2, 16, 0.56315176059205707), (2, 17, 0.68040598104912342), (2, 18, 0.43058700722044946), (2, 19, 0.56906412585246902), (2, 20, 0.42532780243839519), (2, 21, 0.34291883437662118), (2, 22, 0.38765926446726356), (3, 0, 0.65140890578611887), (3, 1, 0.47971625272104002), (3, 2, 0.52443668623073392), (3, 3, 0.0), (3, 4, 0.56742179233292156), (3, 5, 0.31543255742247706), (3, 6, 0.53179004853367595), (3, 7, 0.30441300095764257), (3, 8, 0.7225055774164757), (3, 9, 0.49858156158575018), (3, 10, 0.47647885388690897), (3, 11, 0.86281017980064934), (3, 12, 0.34501607611646706), (3, 13, 0.51315488903197304), (3, 14, 0.60841967705604927), (3, 15, 0.79421854312528783), (3, 16, 0.60949309881590175), (3, 17, 0.54986689528704569), (3, 18, 0.37641649739383304), (3, 19, 0.43250466730651993), (3, 20, 0.68474157746003284), (3, 21, 0.48875847698500047), (3, 22, 0.39164152943184954), (4, 0, 0.49399775280398323), (4, 1, 0.14674814750185905), (4, 2, 0.35203352985456088), (4, 3, 0.56742179233292156), (4, 4, 0.0), (4, 5, 0.29114481502535977), (4, 6, 0.4479485428245964), (4, 7, 0.52309872548924008), (4, 8, 0.38284748859977008), (4, 9, 0.38988967149561393), (4, 10, 0.31114434376538924), (4, 11, 0.44095073043593402), (4, 12, 0.35214621716057098), (4, 13, 0.26210802161544949), (4, 14, 0.22595619897576921), (4, 15, 0.69576800279861895), (4, 16, 0.31808477115511991), (4, 17, 0.61568530953241063), (4, 18, 0.40256345595937748), (4, 19, 0.56094314450546234), (4, 20, 0.41574318194088289), (4, 21, 0.44675104340964034), (4, 22, 0.43586799895116507), (5, 0, 0.51846183726580952), (5, 1, 0.35317581653481867), (5, 2, 0.37541175389780568), (5, 3, 0.31543255742247706), (5, 4, 0.29114481502535977), (5, 5, 0.0), (5, 6, 0.42552885587865397), (5, 7, 0.43635139512286492), (5, 8, 0.47525121730391767), (5, 9, 0.26394425386179315), (5, 10, 0.41007348049572651), (5, 11, 0.61790868328601833), (5, 12, 0.39703963296035838), (5, 13, 0.33525224909219137), (5, 14, 0.4170940561168292), (5, 15, 0.66059034508949876), (5, 16, 0.46709226529300918), (5, 17, 0.53561197677908667), (5, 18, 0.43492371927026202), (5, 19, 0.50119643669197667), (5, 20, 0.56851229674415893), (5, 21, 0.45471173196034315), (5, 22, 0.39778131822333429), (6, 0, 0.47574099780208245), (6, 1, 0.39650503469487058), (6, 2, 0.42325418386701646), (6, 3, 0.53179004853367595), (6, 4, 0.4479485428245964), (6, 5, 0.42552885587865397), (6, 6, 0.0), (6, 7, 0.67153306797755818), (6, 8, 0.40275061240831489), (6, 9, 0.3138875832852398), (6, 10, 0.42337236783642024), (6, 11, 0.47328061532941368), (6, 12, 0.37968655148194114), (6, 13, 0.43873411307907545), (6, 14, 0.46069171421011856), (6, 15, 0.63884162250433785), (6, 16, 0.51312107735498158), (6, 17, 0.59140307527125591), (6, 18, 0.58778341831801784), (6, 19, 0.51716544044998158), (6, 20, 0.48551857371829593), (6, 21, 0.45937944704733991), (6, 22, 0.37799214517708352), (7, 0, 0.45564591065379617), (7, 1, 0.52498495931975242), (7, 2, 0.49418419346336528), (7, 3, 0.30441300095764257), (7, 4, 0.52309872548924008), (7, 5, 0.43635139512286492), (7, 6, 0.67153306797755818), (7, 7, 0.0), (7, 8, 0.63927161537750732), (7, 9, 0.48012817800052904), (7, 10, 0.40365495955373631), (7, 11, 0.87227542741828368), (7, 12, 0.55823645085458629), (7, 13, 0.52156211707833011), (7, 14, 0.57594898009954332), (7, 15, 0.66132221083722587), (7, 16, 0.62160110590457229), (7, 17, 0.54180433886906898), (7, 18, 0.51102962644568262), (7, 19, 0.5843622967883928), (7, 20, 0.76563441295198498), (7, 21, 0.3212160916612597), (7, 22, 0.52816795834266572), (8, 0, 0.56100569446174875), (8, 1, 0.33556985142610146), (8, 2, 0.34194362384899329), (8, 3, 0.7225055774164757), (8, 4, 0.38284748859977008), (8, 5, 0.47525121730391767), (8, 6, 0.40275061240831489), (8, 7, 0.63927161537750732), (8, 8, 0.0), (8, 9, 0.2334243566641129), (8, 10, 0.32139964107832564), (8, 11, 0.5099613660241703), (8, 12, 0.54431608609707594), (8, 13, 0.3957886893612047), (8, 14, 0.5070604154391577), (8, 15, 0.79473248157837928), (8, 16, 0.37895915897978716), (8, 17, 0.83751299546941649), (8, 18, 0.53510227221760076), (8, 19, 0.57729832563853822), (8, 20, 0.55371879765561804), (8, 21, 0.50486877788400841), (8, 22, 0.47197955687836946), (9, 0, 0.34986372615036193), (9, 1, 0.42326318887780884), (9, 2, 0.35332656616677754), (9, 3, 0.49858156158575018), (9, 4, 0.38988967149561393), (9, 5, 0.26394425386179315), (9, 6, 0.3138875832852398), (9, 7, 0.48012817800052904), (9, 8, 0.2334243566641129), (9, 9, 0.0), (9, 10, 0.39161446578345083), (9, 11, 0.56383822188403876), (9, 12, 0.5300930210395437), (9, 13, 0.33856795302106812), (9, 14, 0.44336920562527005), (9, 15, 0.59468883704287889), (9, 16, 0.49864226807302503), (9, 17, 0.58707434972778749), (9, 18, 0.4812550612076254), (9, 19, 0.52566241127820723), (9, 20, 0.63099782619216127), (9, 21, 0.45378099263709776), (9, 22, 0.25491674095666644), (10, 0, 0.51628707009756458), (10, 1, 0.25170210849813784), (10, 2, 0.28002333450382305), (10, 3, 0.47647885388690897), (10, 4, 0.31114434376538924), (10, 5, 0.41007348049572651), (10, 6, 0.42337236783642024), (10, 7, 0.40365495955373631), (10, 8, 0.32139964107832564), (10, 9, 0.39161446578345083), (10, 10, 0.0), (10, 11, 0.45024892415400963), (10, 12, 0.45605396593066955), (10, 13, 0.21805662930135758), (10, 14, 0.29510232045836954), (10, 15, 0.80037634953481784), (10, 16, 0.4230239046424995), (10, 17, 0.70268990168329037), (10, 18, 0.46860127414391883), (10, 19, 0.51151346155794764), (10, 20, 0.4580889347312308), (10, 21, 0.3229907000758323), (10, 22, 0.38241447811329515), (11, 0, 0.52973107702094779), (11, 1, 0.50786656419891174), (11, 2, 0.54365357049699736), (11, 3, 0.86281017980064934), (11, 4, 0.44095073043593402), (11, 5, 0.61790868328601833), (11, 6, 0.47328061532941368), (11, 7, 0.87227542741828368), (11, 8, 0.5099613660241703), (11, 9, 0.56383822188403876), (11, 10, 0.45024892415400963), (11, 11, 0.0), (11, 12, 0.50242376610747597), (11, 13, 0.41584815273405495), (11, 14, 0.40733416137827094), (11, 15, 0.73556692635932697), (11, 16, 0.54305369694742189), (11, 17, 0.74179839209109044), (11, 18, 0.68450105507228098), (11, 19, 0.7274844742701061), (11, 20, 0.12951048657989928), (11, 21, 0.70647247392902524), (11, 22, 0.53800653701025847), (12, 0, 0.53890227211158004), (12, 1, 0.38777266026135659), (12, 2, 0.51639393870232375), (12, 3, 0.34501607611646706), (12, 4, 0.35214621716057098), (12, 5, 0.39703963296035838), (12, 6, 0.37968655148194114), (12, 7, 0.55823645085458629), (12, 8, 0.54431608609707594), (12, 9, 0.5300930210395437), (12, 10, 0.45605396593066955), (12, 11, 0.50242376610747597), (12, 12, 0.0), (12, 13, 0.37625493773490826), (12, 14, 0.37685358437550348), (12, 15, 0.74048699903821891), (12, 16, 0.38180100054370814), (12, 17, 0.59759169608333385), (12, 18, 0.44285156692992955), (12, 19, 0.47453893720112528), (12, 20, 0.39913140248826484), (12, 21, 0.45840214638230398), (12, 22, 0.42204485699376332), (13, 0, 0.5146657333157868), (13, 1, 0.25692128786469992), (13, 2, 0.43429166784441947), (13, 3, 0.51315488903197304), (13, 4, 0.26210802161544949), (13, 5, 0.33525224909219137), (13, 6, 0.43873411307907545), (13, 7, 0.52156211707833011), (13, 8, 0.3957886893612047), (13, 9, 0.33856795302106812), (13, 10, 0.21805662930135758), (13, 11, 0.41584815273405495), (13, 12, 0.37625493773490826), (13, 13, 0.0), (13, 14, 0.38966057127809889), (13, 15, 0.68524367549896348), (13, 16, 0.35786462046910977), (13, 17, 0.55739961533249816), (13, 18, 0.43215852866455962), (13, 19, 0.48290482801912427), (13, 20, 0.45088786586652407), (13, 21, 0.54727324042890324), (13, 22, 0.40760332156802259), (14, 0, 0.49736924475057098), (14, 1, 0.33276004667472148), (14, 2, 0.29338742478788299), (14, 3, 0.60841967705604927), (14, 4, 0.22595619897576921), (14, 5, 0.4170940561168292), (14, 6, 0.46069171421011856), (14, 7, 0.57594898009954332), (14, 8, 0.5070604154391577), (14, 9, 0.44336920562527005), (14, 10, 0.29510232045836954), (14, 11, 0.40733416137827094), (14, 12, 0.37685358437550348), (14, 13, 0.38966057127809889), (14, 14, 0.0), (14, 15, 0.72743443867537405), (14, 16, 0.50315906205982708), (14, 17, 0.68401492142167397), (14, 18, 0.56160851044445059), (14, 19, 0.68208202141875163), (14, 20, 0.35862630751028923), (14, 21, 0.39067534762983608), (14, 22, 0.43497154115443737), (15, 0, 0.58248789556331948), (15, 1, 0.68471966667506567), (15, 2, 0.75754074934714755), (15, 3, 0.79421854312528783), (15, 4, 0.69576800279861895), (15, 5, 0.66059034508949876), (15, 6, 0.63884162250433785), (15, 7, 0.66132221083722587), (15, 8, 0.79473248157837928), (15, 9, 0.59468883704287889), (15, 10, 0.80037634953481784), (15, 11, 0.73556692635932697), (15, 12, 0.74048699903821891), (15, 13, 0.68524367549896348), (15, 14, 0.72743443867537405), (15, 15, 0.0), (15, 16, 0.54237228995135156), (15, 17, 0.13148068885144523), (15, 18, 0.65497569556099522), (15, 19, 0.78211224111218225), (15, 20, 0.82019672751799333), (15, 21, 0.80411048743853286), (15, 22, 0.65617423221241789), (16, 0, 0.6776139772034957), (16, 1, 0.41580975061245135), (16, 2, 0.56315176059205707), (16, 3, 0.60949309881590175), (16, 4, 0.31808477115511991), (16, 5, 0.46709226529300918), (16, 6, 0.51312107735498158), (16, 7, 0.62160110590457229), (16, 8, 0.37895915897978716), (16, 9, 0.49864226807302503), (16, 10, 0.4230239046424995), (16, 11, 0.54305369694742189), (16, 12, 0.38180100054370814), (16, 13, 0.35786462046910977), (16, 14, 0.50315906205982708), (16, 15, 0.54237228995135156), (16, 16, 0.0), (16, 17, 0.47668042380557074), (16, 18, 0.21102509342242082), (16, 19, 0.47617831381534542), (16, 20, 0.62938039887983721), (16, 21, 0.43938904572216364), (16, 22, 0.59909480157882811), (17, 0, 0.52597275949718791), (17, 1, 0.62937213092971744), (17, 2, 0.68040598104912342), (17, 3, 0.54986689528704569), (17, 4, 0.61568530953241063), (17, 5, 0.53561197677908667), (17, 6, 0.59140307527125591), (17, 7, 0.54180433886906898), (17, 8, 0.83751299546941649), (17, 9, 0.58707434972778749), (17, 10, 0.70268990168329037), (17, 11, 0.74179839209109044), (17, 12, 0.59759169608333385), (17, 13, 0.55739961533249816), (17, 14, 0.68401492142167397), (17, 15, 0.13148068885144523), (17, 16, 0.47668042380557074), (17, 17, 0.0), (17, 18, 0.46037820526638518), (17, 19, 0.50702025372579862), (17, 20, 0.80905650349213198), (17, 21, 0.68959648657423633), (17, 22, 0.5001927827018301), (18, 0, 0.71594709571336135), (18, 1, 0.5025238787123274), (18, 2, 0.43058700722044946), (18, 3, 0.37641649739383304), (18, 4, 0.40256345595937748), (18, 5, 0.43492371927026202), (18, 6, 0.58778341831801784), (18, 7, 0.51102962644568262), (18, 8, 0.53510227221760076), (18, 9, 0.4812550612076254), (18, 10, 0.46860127414391883), (18, 11, 0.68450105507228098), (18, 12, 0.44285156692992955), (18, 13, 0.43215852866455962), (18, 14, 0.56160851044445059), (18, 15, 0.65497569556099522), (18, 16, 0.21102509342242082), (18, 17, 0.46037820526638518), (18, 18, 0.0), (18, 19, 0.38560283864650524), (18, 20, 0.68485744675676563), (18, 21, 0.4598443034604871), (18, 22, 0.42204446560192932), (19, 0, 0.42486033117478794), (19, 1, 0.53638794936262513), (19, 2, 0.56906412585246902), (19, 3, 0.43250466730651993), (19, 4, 0.56094314450546234), (19, 5, 0.50119643669197667), (19, 6, 0.51716544044998158), (19, 7, 0.5843622967883928), (19, 8, 0.57729832563853822), (19, 9, 0.52566241127820723), (19, 10, 0.51151346155794764), (19, 11, 0.7274844742701061), (19, 12, 0.47453893720112528), (19, 13, 0.48290482801912427), (19, 14, 0.68208202141875163), (19, 15, 0.78211224111218225), (19, 16, 0.47617831381534542), (19, 17, 0.50702025372579862), (19, 18, 0.38560283864650524), (19, 19, 0.0), (19, 20, 0.7580487163162184), (19, 21, 0.52163858836764165), (19, 22, 0.40768785703048355), (20, 0, 0.64032603774521635), (20, 1, 0.4018784228699489), (20, 2, 0.42532780243839519), (20, 3, 0.68474157746003284), (20, 4, 0.41574318194088289), (20, 5, 0.56851229674415893), (20, 6, 0.48551857371829593), (20, 7, 0.76563441295198498), (20, 8, 0.55371879765561804), (20, 9, 0.63099782619216127), (20, 10, 0.4580889347312308), (20, 11, 0.12951048657989928), (20, 12, 0.39913140248826484), (20, 13, 0.45088786586652407), (20, 14, 0.35862630751028923), (20, 15, 0.82019672751799333), (20, 16, 0.62938039887983721), (20, 17, 0.80905650349213198), (20, 18, 0.68485744675676563), (20, 19, 0.7580487163162184), (20, 20, 0.0), (20, 21, 0.69730093475331945), (20, 22, 0.57113461601792992), (21, 0, 0.47914415732892879), (21, 1, 0.61038742489197018), (21, 2, 0.34291883437662118), (21, 3, 0.48875847698500047), (21, 4, 0.44675104340964034), (21, 5, 0.45471173196034315), (21, 6, 0.45937944704733991), (21, 7, 0.3212160916612597), (21, 8, 0.50486877788400841), (21, 9, 0.45378099263709776), (21, 10, 0.3229907000758323), (21, 11, 0.70647247392902524), (21, 12, 0.45840214638230398), (21, 13, 0.54727324042890324), (21, 14, 0.39067534762983608), (21, 15, 0.80411048743853286), (21, 16, 0.43938904572216364), (21, 17, 0.68959648657423633), (21, 18, 0.4598443034604871), (21, 19, 0.52163858836764165), (21, 20, 0.69730093475331945), (21, 21, 0.0), (21, 22, 0.56257398468603748), (22, 0, 0.39969541644011874), (22, 1, 0.39371461198239027), (22, 2, 0.38765926446726356), (22, 3, 0.39164152943184954), (22, 4, 0.43586799895116507), (22, 5, 0.39778131822333429), (22, 6, 0.37799214517708352), (22, 7, 0.52816795834266572), (22, 8, 0.47197955687836946), (22, 9, 0.25491674095666644), (22, 10, 0.38241447811329515), (22, 11, 0.53800653701025847), (22, 12, 0.42204485699376332), (22, 13, 0.40760332156802259), (22, 14, 0.43497154115443737), (22, 15, 0.65617423221241789), (22, 16, 0.59909480157882811), (22, 17, 0.5001927827018301), (22, 18, 0.42204446560192932), (22, 19, 0.40768785703048355), (22, 20, 0.57113461601792992), (22, 21, 0.56257398468603748), (22, 22, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "# Constructing JS Matrix\n",
    "\n",
    "# Creates a list containing 5 lists, each of 8 items, all set to 0\n",
    "w, h = 23, 23 \n",
    "Matrix = [[0 for x in range(w)] for y in range(h)] \n",
    "\n",
    "JSM = list()\n",
    "js_df = pd.DataFrame()\n",
    "\n",
    "# for index1,item1 in enumerate(doc_topic):\n",
    "#     JSM[:] = []\n",
    "#     for index2,item2 in enumerate(doc_topic):\n",
    "#         result = jsd(doc_topic[index1],doc_topic[index2])\n",
    "#         JSM.append(result)\n",
    "#         js_df = pd.DataFrame(JSM)\n",
    "#         js_df = js_df.transpose()\n",
    "#     js_df1.append(js_df)\n",
    "# #     js_df.loc[index1] = pd.DataFrame.append(JSM)\n",
    "\n",
    "# print(js_df1)\n",
    "\n",
    "# len(df.columns) = 23\n",
    "\n",
    "\n",
    "# for index1,item1 in enumerate(doc_topic):\n",
    "#     for index2,item2 in enumerate(doc_topic):\n",
    "#         result = jsd(doc_topic[index1],doc_topic[index2])\n",
    "#         js_df[index1,index2] = pd.DataFrame(result)\n",
    "        \n",
    "# print(js_df)\n",
    "\n",
    "\n",
    "for index1,item1 in enumerate(doc_topic):\n",
    "    for index2,item2 in enumerate(doc_topic):\n",
    "        result = jsd(doc_topic[index1],doc_topic[index2])\n",
    "        Matrix[index1][index2] = result\n",
    "        temp_list = list()        \n",
    "        temp_list = (index1,index2,result)\n",
    "        JSM.append(temp_list)\n",
    "\n",
    "print(JSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Writing to a txt file for Mapequation\n",
    "\n",
    "# JS_str = str(JSM)\n",
    "\n",
    "text_file = open(\"/Users/tarunruchandani/Desktop/HarvardSummer2016/mymaps/JS_output1.txt\", \"w\")\n",
    "\n",
    "for index1,item1 in enumerate(doc_topic):\n",
    "    for index2,item2 in enumerate(doc_topic):\n",
    "        result = jsd(doc_topic[index1],doc_topic[index2])\n",
    "        text_file.write(\"%s %s %s\\n\" %(index1, index2, result))\n",
    "\n",
    "text_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
